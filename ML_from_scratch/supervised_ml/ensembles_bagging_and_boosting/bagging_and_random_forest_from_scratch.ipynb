{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/priyanuj/CampusX_ML_Course/ridge_regression_from_scratch_ols.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Multiple_Linear_Regression_0520.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/train_digit.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/Titanic_Survival_Analysis_10212023.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/ridge_regression_from_scratch_gradient_descent_methodology.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Gradient_Descent_function_video_1_first_code.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/test.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/decision_tree_clf_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/PCA_102123.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/perceptron_trick_code_classification.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/kNNClassifier_from_scratch_1012.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/logistic_regression_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/train.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/test_digit.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/train_data.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/roc_auc_code_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Social_Network_Ads.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/test_data.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/ridge_regression_from_scratch_ols-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/perceptron_trick_code_classification-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/PCA_102123-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/roc_auc_code_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/logistic_regression_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/kNNClassifier_from_scratch_1012-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Titanic_Survival_Analysis_10212023-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Gradient_Descent_function_video_1_first_code-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/ridge_regression_from_scratch_gradient_descent_methodology-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/decision_tree_clf_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Multiple_Linear_Regression_0520-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Checking for files in the required location\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/priyanuj/CampusX_ML_Course'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            1         0    1  0.2750  0.014151         0         0         1   \n",
       "1            2         1    0  0.4750  0.139136         1         0         0   \n",
       "2            3         1    0  0.3250  0.015469         0         0         1   \n",
       "3            4         1    0  0.4375  0.103644         1         0         0   \n",
       "4            5         0    1  0.4375  0.015713         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      0      0      1  \n",
       "1          0.1      1      0      0  \n",
       "2          0.0      0      0      1  \n",
       "3          0.1      0      0      1  \n",
       "4          0.0      0      0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing titanic data from the required location\n",
    "input_ads_pre = pd.read_csv('/Users/priyanuj/CampusX_ML_Course/train_data.csv')\n",
    "input_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True)\n",
    "#----------------------------------------------------------------------------------------------\n",
    "print(input_ads_pre.shape)\n",
    "input_ads_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    486\n",
       "1    306\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total survived vs not-survived count/split in the training data\n",
    "input_ads_pre['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex  Age  Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            0         0    0    0     0         0         0         0   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0            0      0      0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_ads_pre.isnull().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.368244</td>\n",
       "      <td>0.064677</td>\n",
       "      <td>0.243687</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.092172</td>\n",
       "      <td>0.720960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>228.774999</td>\n",
       "      <td>0.487223</td>\n",
       "      <td>0.477980</td>\n",
       "      <td>0.162994</td>\n",
       "      <td>0.100987</td>\n",
       "      <td>0.429577</td>\n",
       "      <td>0.406373</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>0.154485</td>\n",
       "      <td>0.389034</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.448811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>198.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>594.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Sex         Age        Fare  \\\n",
       "count   792.000000  792.000000  792.000000  792.000000  792.000000   \n",
       "mean    396.500000    0.386364    0.647727    0.368244    0.064677   \n",
       "std     228.774999    0.487223    0.477980    0.162994    0.100987   \n",
       "min       1.000000    0.000000    0.000000    0.008375    0.000000   \n",
       "25%     198.750000    0.000000    0.000000    0.275000    0.015469   \n",
       "50%     396.500000    0.000000    1.000000    0.350000    0.028302   \n",
       "75%     594.250000    1.000000    1.000000    0.437500    0.061045   \n",
       "max     792.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Pclass_1    Pclass_2    Pclass_3  Family_size       Emb_1  \\\n",
       "count  792.000000  792.000000  792.000000   792.000000  792.000000   \n",
       "mean     0.243687    0.208333    0.547980     0.088636    0.185606   \n",
       "std      0.429577    0.406373    0.498007     0.154485    0.389034   \n",
       "min      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000     0.000000    0.000000   \n",
       "75%      0.000000    0.000000    1.000000     0.100000    0.000000   \n",
       "max      1.000000    1.000000    1.000000     1.000000    1.000000   \n",
       "\n",
       "            Emb_2       Emb_3  \n",
       "count  792.000000  792.000000  \n",
       "mean     0.092172    0.720960  \n",
       "std      0.289451    0.448811  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      0.000000    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads_pre.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.123667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0          371         1    1  0.3125  0.108215         1         0         0   \n",
       "1          556         0    1  0.7750  0.051822         1         0         0   \n",
       "2          624         0    1  0.2625  0.015330         0         0         1   \n",
       "3           98         1    1  0.2875  0.123667         1         0         0   \n",
       "4          144         0    1  0.2375  0.013175         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      1      0      0  \n",
       "1          0.0      0      0      1  \n",
       "2          0.0      0      0      1  \n",
       "3          0.1      1      0      0  \n",
       "4          0.0      0      1      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "input_ads = shuffle(input_ads_pre, random_state = 100)\n",
    "input_ads.reset_index(drop=True, inplace = True)\n",
    "print(input_ads.shape)\n",
    "input_ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulation of data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train % of total data: 88.78923766816143\n",
      "(792, 11)\n",
      "(100, 11)\n",
      "(792, 1)\n"
     ]
    }
   ],
   "source": [
    "target = 'Survived' #To predict\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Splitting into X & Y datasets (supervised training)\n",
    "X = input_ads[[cols for cols in list(input_ads.columns) if target not in cols]]\n",
    "y = input_ads[target]\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Since test data is already placed in the input folder separately, we will just import it\n",
    "test_ads_pre = pd.read_csv('/Users/priyanuj/CampusX_ML_Course/test_data.csv')\n",
    "test_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\n",
    "test_ads = shuffle(test_ads_pre,random_state=100)\n",
    "test_ads = test_ads.reset_index(drop=True)\n",
    "\n",
    "#Splitting into X & Y datasets (supervised training)\n",
    "X_test = test_ads[[cols for cols in list(test_ads.columns) if target not in cols]]\n",
    "y_test = test_ads[target]\n",
    "\n",
    "print('Train % of total data:',100 * X.shape[0]/(X.shape[0] + X_test.shape[0]))\n",
    "#--------------------------------------------------------------------------------\n",
    "#Manipulation of datasets for convenience and consistency\n",
    "X_arr = np.array(X)\n",
    "X_test_arr = np.array(X_test)\n",
    "\n",
    "y_arr = np.array(y).reshape(X_arr.shape[0],1)\n",
    "y_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Basic Summary\n",
    "print(X_arr.shape)\n",
    "print(X_test_arr.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Logistic Regression and Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#- Decision Tree ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.7986111111111112\n",
      "Accuracy of test set : 0.82 \n",
      "\n",
      "#- Logistic Regression ---------------------------------------------#\n",
      "ROC AUC of test set : 0.5\n",
      "Accuracy of test set : 0.64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "#max_depth=2,min_samples_split=7,min_samples_leaf=8,\n",
    "\n",
    "#Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=100)\n",
    "dt_clf.fit(X_arr,y_arr)\n",
    "sklearn_preds_dt = dt_clf.predict(X_test_arr)\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#Logistic Regression\n",
    "lr_clf = LogisticRegression(solver='sag',random_state=100)\n",
    "lr_clf.fit(X_arr,y_arr)\n",
    "sklearn_preds_lr = lr_clf.predict(X_test_arr)\n",
    "\n",
    "#Evaluation of the predictions\n",
    "print('#- Decision Tree ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,sklearn_preds_dt))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,sklearn_preds_dt),'\\n')\n",
    "\n",
    "print('#- Logistic Regression ---------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,sklearn_preds_lr))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,sklearn_preds_lr),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Logic from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for bootstrap sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UDF for bootstrapping sampling logic\n",
    "def bootstrapped_sample(arr,random_state):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    # The function is mentioned such as way that, with replacement, the total number of rows will be equal to the \n",
    "    # number of rows in the array/ dataset provided\n",
    "    boot_sample_idx = np.random.choice(a=range(len(arr)),size=len(arr),replace=True)\n",
    "    boot_sample = arr[boot_sample_idx]\n",
    "    \n",
    "    return boot_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for bagging (will work similarly for regression as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_ensemble_clf(n_estimators, estimator, X_arr_, y_arr_, test, threshold = 0.5):\n",
    "    \n",
    "    pred_array = np.array([np.nan]*len(test)).reshape((len(test)),1)\n",
    "    \n",
    "    joint_arr = np.append(X_arr_, y_arr_, axis = -1)\n",
    "    \n",
    "    # Bootstrapping and building the model iteratively\n",
    "    \n",
    "    for n in range(n_estimators):\n",
    "        # using random state = n gives more randomness per iteration for selection of points\n",
    "        sample = bootstrapped_sample(joint_arr, random_state = n)\n",
    "        \n",
    "        X_sample = sample[:,0:-1]\n",
    "        y_sample = sample[:,-1]\n",
    "        \n",
    "        #fitting the estimator\n",
    "        estimator.fit(X_sample, y_sample)\n",
    "        \n",
    "        pred_array_temp = np.array(estimator.predict(test)).reshape((len(test)),1)\n",
    "        # adding the predictions from the subsequent estimators to the array as columns\n",
    "        pred_array = np.append(pred_array, pred_array_temp, axis = -1)\n",
    "        \n",
    "        \n",
    "    # Aggregation\n",
    "    # Removing the first column which contains nan values as defined in the first snippet\n",
    "    pred_array = pred_array[:,1:]\n",
    "    # aggregating the predictions from the estimators\n",
    "    pred = np.sum(pred_array, axis = 1)\n",
    "    \n",
    "    n_preds = pred_array.shape[1] #Total number of columns\n",
    "    \n",
    "    pred = pred/n_preds\n",
    "    \n",
    "    pred = (pred>threshold).astype(int)\n",
    "    print('Unique Preditions: ', np.unique(pred))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating the bagging udf with decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Preditions:  [0 1]\n",
      "(100,)\n",
      "#- Manual Bagging w/ Decision Tree ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.8081597222222222\n",
      "Accuracy of test set : 0.84 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "preds_dt = bagging_ensemble_clf(n_estimators=500, estimator=decision_tree, X_arr_=X_arr, y_arr_=y_arr, test=X_test_arr)\n",
    "print(preds_dt.shape)\n",
    "\n",
    "print('#- Manual Bagging w/ Decision Tree ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_dt))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,preds_dt),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiating the bagging udf with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Preditions:  [0]\n",
      "(100,)\n",
      "#- Manual Bagging w/ Logistic Regression Tree ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.5\n",
      "Accuracy of test set : 0.64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='saga',random_state=100)\n",
    "\n",
    "preds_lr = bagging_ensemble_clf(n_estimators=500, estimator=log_reg, X_arr_=X_arr, y_arr_=y_arr, test=X_test_arr)\n",
    "print(preds_lr.shape)\n",
    "\n",
    "print('#- Manual Bagging w/ Logistic Regression Tree ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_lr))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,preds_lr),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier - can have only decision trees and needs sampling of columns too at each node hence will use max_featuers. = 'sqrt' at each node for column splitting with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Preditions:  [0 1]\n",
      "(100,)\n",
      "#- Manual Random Forest ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.8081597222222222\n",
      "Accuracy of test set : 0.84 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_with_col_sampling = DecisionTreeClassifier(max_features='sqrt', random_state=100)\n",
    "\n",
    "preds_rf = bagging_ensemble_clf(n_estimators=500, estimator=decision_tree_with_col_sampling, X_arr_=X_arr, y_arr_=y_arr, test=X_test_arr)\n",
    "print(preds_rf.shape)\n",
    "\n",
    "print('#- Manual Random Forest ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,preds_dt))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,preds_dt),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#- Sklearn Bagging Classifier ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.8081597222222222\n",
      "Accuracy of test set : 0.84 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=100)\n",
    "\n",
    "bagging_skl = BaggingClassifier(base_estimator=decision_tree,\n",
    "                                n_estimators=500,\n",
    "                                max_features=1.0,\n",
    "                                bootstrap=True,\n",
    "                                random_state=100,\n",
    "                                n_jobs=-1)\n",
    "bagging_skl.fit(X_arr,y_arr)\n",
    "bagging_skl_pred = bagging_skl.predict(X_test_arr)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "print('#- Sklearn Bagging Classifier ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,bagging_skl_pred))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,bagging_skl_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#- Sklearn Bagging Classifier ---------------------------------------------------#\n",
      "ROC AUC of test set : 0.828125\n",
      "Accuracy of test set : 0.85 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_skl = RandomForestClassifier(n_estimators=500,\n",
    "                                max_features='sqrt',\n",
    "                                bootstrap=True,\n",
    "                                random_state=100,\n",
    "                                n_jobs=-1)\n",
    "rf_skl.fit(X_arr,y_arr)\n",
    "rf_skl_pred = rf_skl.predict(X_test_arr)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "print('#- Sklearn Bagging Classifier ---------------------------------------------------#')\n",
    "print('ROC AUC of test set :',roc_auc_score(y_test_arr,rf_skl_pred))\n",
    "print('Accuracy of test set :',accuracy_score(y_test_arr,rf_skl_pred),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights : The manual implementations are giving almost identical quality of predictions for normal bagging and random forest with the sklearn versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
