{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing down the filenames/ csv files from the required location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/priyanuj/CampusX_ML_Course/ridge_regression_from_scratch_ols.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Multiple_Linear_Regression_0520.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/train_digit.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/Titanic_Survival_Analysis_10212023.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/ridge_regression_from_scratch_gradient_descent_methodology.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Gradient_Descent_function_video_1_first_code.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/test.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/decision_tree_clf_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/PCA_102123.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/perceptron_trick_code_classification.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/kNNClassifier_from_scratch_1012.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/logistic_regression_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/train.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/test_digit.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/train_data.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/roc_auc_code_from_scratch.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/Social_Network_Ads.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/test_data.csv\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/ridge_regression_from_scratch_ols-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/perceptron_trick_code_classification-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/PCA_102123-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/roc_auc_code_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/logistic_regression_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/kNNClassifier_from_scratch_1012-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Titanic_Survival_Analysis_10212023-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Gradient_Descent_function_video_1_first_code-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/ridge_regression_from_scratch_gradient_descent_methodology-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/decision_tree_clf_from_scratch-checkpoint.ipynb\n",
      "/Users/priyanuj/CampusX_ML_Course/.ipynb_checkpoints/Multiple_Linear_Regression_0520-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/Users/priyanuj/CampusX_ML_Course'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing titanic train and test data from the location and then dropping the un-necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived  Sex     Age      Fare  Pclass_1  \\\n",
       "0           0            1         0    1  0.2750  0.014151         0   \n",
       "1           1            2         1    0  0.4750  0.139136         1   \n",
       "2           2            3         1    0  0.3250  0.015469         0   \n",
       "3           3            4         1    0  0.4375  0.103644         1   \n",
       "4           4            5         0    1  0.4375  0.015713         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  Family_size  Title_1  Title_2  Title_3  Title_4  Emb_1  \\\n",
       "0         0         1          0.1        1        0        0        0      0   \n",
       "1         0         0          0.1        1        0        0        0      1   \n",
       "2         0         1          0.0        0        0        0        1      0   \n",
       "3         0         0          0.1        1        0        0        0      0   \n",
       "4         0         1          0.0        1        0        0        0      0   \n",
       "\n",
       "   Emb_2  Emb_3  \n",
       "0      0      1  \n",
       "1      0      0  \n",
       "2      0      1  \n",
       "3      0      1  \n",
       "4      0      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing titanic data from the required location\n",
    "input_ads_pre = pd.read_csv('/Users/priyanuj/CampusX_ML_Course/train_data.csv')\n",
    "print(input_ads_pre.shape)\n",
    "input_ads_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            1         0    1  0.2750  0.014151         0         0         1   \n",
       "1            2         1    0  0.4750  0.139136         1         0         0   \n",
       "2            3         1    0  0.3250  0.015469         0         0         1   \n",
       "3            4         1    0  0.4375  0.103644         1         0         0   \n",
       "4            5         0    1  0.4375  0.015713         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      0      0      1  \n",
       "1          0.1      1      0      0  \n",
       "2          0.0      0      0      1  \n",
       "3          0.1      0      0      1  \n",
       "4          0.0      0      0      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads_pre.drop(columns = ['Unnamed: 0', 'Title_1', 'Title_2', 'Title_3', 'Title_4'], axis = 1, inplace = True)\n",
    "input_ads_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex  Age  Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            0         0    0    0     0         0         0         0   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0            0      0      0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_ads_pre.isnull().sum()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.368244</td>\n",
       "      <td>0.064677</td>\n",
       "      <td>0.243687</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.092172</td>\n",
       "      <td>0.720960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>228.774999</td>\n",
       "      <td>0.487223</td>\n",
       "      <td>0.477980</td>\n",
       "      <td>0.162994</td>\n",
       "      <td>0.100987</td>\n",
       "      <td>0.429577</td>\n",
       "      <td>0.406373</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>0.154485</td>\n",
       "      <td>0.389034</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.448811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>198.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>594.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Sex         Age        Fare  \\\n",
       "count   792.000000  792.000000  792.000000  792.000000  792.000000   \n",
       "mean    396.500000    0.386364    0.647727    0.368244    0.064677   \n",
       "std     228.774999    0.487223    0.477980    0.162994    0.100987   \n",
       "min       1.000000    0.000000    0.000000    0.008375    0.000000   \n",
       "25%     198.750000    0.000000    0.000000    0.275000    0.015469   \n",
       "50%     396.500000    0.000000    1.000000    0.350000    0.028302   \n",
       "75%     594.250000    1.000000    1.000000    0.437500    0.061045   \n",
       "max     792.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Pclass_1    Pclass_2    Pclass_3  Family_size       Emb_1  \\\n",
       "count  792.000000  792.000000  792.000000   792.000000  792.000000   \n",
       "mean     0.243687    0.208333    0.547980     0.088636    0.185606   \n",
       "std      0.429577    0.406373    0.498007     0.154485    0.389034   \n",
       "min      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000     0.000000    0.000000   \n",
       "75%      0.000000    0.000000    1.000000     0.100000    0.000000   \n",
       "max      1.000000    1.000000    1.000000     1.000000    1.000000   \n",
       "\n",
       "            Emb_2       Emb_3  \n",
       "count  792.000000  792.000000  \n",
       "mean     0.092172    0.720960  \n",
       "std      0.289451    0.448811  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      0.000000    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads_pre.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    486\n",
       "1    306\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total survived vs not-survived split in the training data\n",
    "input_ads_pre['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.123667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0          371         1    1  0.3125  0.108215         1         0         0   \n",
       "1          556         0    1  0.7750  0.051822         1         0         0   \n",
       "2          624         0    1  0.2625  0.015330         0         0         1   \n",
       "3           98         1    1  0.2875  0.123667         1         0         0   \n",
       "4          144         0    1  0.2375  0.013175         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      1      0      0  \n",
       "1          0.0      0      0      1  \n",
       "2          0.0      0      0      1  \n",
       "3          0.1      1      0      0  \n",
       "4          0.0      0      1      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "input_ads = shuffle(input_ads_pre, random_state = 100)\n",
    "print(input_ads.shape)\n",
    "input_ads.reset_index(drop = True, inplace = True)\n",
    "input_ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation of Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Sex', 'Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
      "       'Family_size', 'Emb_1', 'Emb_2', 'Emb_3'],\n",
      "      dtype='object')\n",
      "Train % of total data:  88.78923766816143\n",
      "(792, 11)\n",
      "(100, 11)\n",
      "(792, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "target = 'Survived'\n",
    "\n",
    "X = input_ads[[cols for cols in list(input_ads.columns) if target not in cols]]\n",
    "y = input_ads[target]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Since test data is placed in the input foler separately, we will import the test data set\n",
    "test_ads_pre = pd.read_csv('/Users/priyanuj/CampusX_ML_Course/test_data.csv')\n",
    "test_ads_pre.drop(columns = ['Unnamed: 0', 'Title_1', 'Title_2', 'Title_3', 'Title_4'], axis = 1, inplace = True)\n",
    "test_ads = shuffle(test_ads_pre, random_state = 100)\n",
    "test_ads.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Splitting test dataset into X and y datasets (for supervised learning)\n",
    "X_test = test_ads[[cols for cols in list(test_ads.columns) if target not in cols]]\n",
    "y_test = test_ads[target]\n",
    "\n",
    "print('Train % of total data: ', 100*X.shape[0]/ (X.shape[0] + X_test.shape[0]))\n",
    "\n",
    "# Manipulation of datasets for convenience and consistency\n",
    "\n",
    "X_arr = np.array(X)\n",
    "X_test_arr = np.array(X_test)\n",
    "\n",
    "y_arr = np.array(y).reshape(X_arr.shape[0],1)\n",
    "y_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n",
    "\n",
    "# Summary\n",
    "print(X_arr.shape)\n",
    "print(X_test.shape)\n",
    "print(y_arr.shape)\n",
    "print(y_test_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF to calculate gini index of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = unique number of classes defined in a later function\n",
    "def gini_node(arr_, k):\n",
    "    \n",
    "    class_elem_total = 0\n",
    "    for class_ in k: #Iterating through each class in the node\n",
    "        class_elem = (np.sum((arr_==class_).astype(int)))/(len(arr_))  # arr_ == 0 will give true or false and hence sum will work for both classes\n",
    "        class_elem = class_elem**2\n",
    "        class_elem_total = class_elem_total + class_elem\n",
    "    \n",
    "    gini_node = 1 - class_elem_total\n",
    "    return gini_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for gini index of a split (weighted by leafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_split(left_arr, right_arr, k):\n",
    "    \n",
    "    # Total observations in each node\n",
    "    m_left = len(left_arr)\n",
    "    m_right = len(right_arr)\n",
    "    m_total_node = m_left + m_right\n",
    "    \n",
    "    \n",
    "    # Calculating gini index at each node\n",
    "    gini_left = gini_node(left_arr, k)\n",
    "    \n",
    "    gini_right = gini_node(right_arr, k)\n",
    "    \n",
    "    # calculation of gini for the split\n",
    "    \n",
    "    if m_left == 0:\n",
    "        gini_split = ((m_right/m_total_node) * gini_right)\n",
    "        \n",
    "    elif m_right == 0:\n",
    "        gini_split = ((m_left/m_total_node) * gini_left)\n",
    "        \n",
    "    elif (m_left>0) & (m_right>0):\n",
    "        gini_split = ((m_left/m_total_node) * gini_left) + ((m_right/m_total_node) * gini_right)\n",
    "    \n",
    "    return gini_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for finding best split for a feature, greedy exact search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_split_algo(data, col_idx, min_samples_split = 2, min_samples_leaf = 2):\n",
    "    \n",
    "    assert len(data[:, col_idx]) >= min_samples_split, \"Data Insufficient -  Either include more data or reduce min_samples_split hyper-parameter\"\n",
    "    \n",
    "    k = np.unique(data[:, -1]) #unique of all classes going into function\n",
    "    \n",
    "    # To be used for thresholds\n",
    "    unique_vals = np.unique(data[:, col_idx])\n",
    "    \n",
    "    \n",
    "    if len(unique_vals) > 1: # because if all values are same, there is no point in splitting with that column\n",
    "        \n",
    "        gini_node_ = gini_node(data[:, -1], k)\n",
    "        \n",
    "        splits_gini_dict = {}\n",
    "        thresholds_discarded = []\n",
    "        \n",
    "        for threshold in unique_vals: # For each threshold possible\n",
    "            \n",
    "            left_split = data[data[:, col_idx] <= threshold] # Left extension of the tree\n",
    "            left_split_target = left_split[:,-1]\n",
    "            \n",
    "            right_split = data[data[:, col_idx] > threshold] # Left extension of the tree\n",
    "            right_split_target = right_split[:,-1]\n",
    "            \n",
    "            if (len(left_split_target) > min_samples_leaf) and (len(right_split_target) > min_samples_leaf): #Condition on mininum samples for a split to be eligible\n",
    "                \n",
    "                gini_split_ = gini_split(left_arr = left_split_target, right_arr = right_split_target, k = k)\n",
    "                \n",
    "                splits_gini_dict.update({threshold :  gini_split_}) #weighted gini of right and left node for each split\n",
    "                \n",
    "            else:\n",
    "                # Discarding the threshold if condition not met\n",
    "                thresholds_discarded.append(threshold)\n",
    "                \n",
    "        # Condition to avoid empty dictionary (if no split is feasible)\n",
    "        if len(splits_gini_dict) > 0:\n",
    "            \n",
    "            min_gini = min(splits_gini_dict.values())\n",
    "            \n",
    "            # it is the threshold or the splitting value\n",
    "            split_val = [key for key in splits_gini_dict if splits_gini_dict[key] == min_gini]\n",
    "            \n",
    "            # here we are obtaining the value of the split for the column where the gini impurity is minimum\n",
    "            # for the column, we got the value of the splitting condition\n",
    "            split_col_map_dict = {col_idx : split_val[0]}\n",
    "            # for the column we got the value of the gini as well\n",
    "            best_score_col_map_dict = {col_idx : min_gini}\n",
    "            \n",
    "            return split_col_map_dict, best_score_col_map_dict\n",
    "        \n",
    "        else:\n",
    "            split_col_map_dict = {col_idx : np.nan}\n",
    "            \n",
    "            best_score_col_map_dict = {col_idx : np.nan}\n",
    "            \n",
    "            return split_col_map_dict, best_score_col_map_dict\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        split_col_map_dict = {col_idx : np.nan}\n",
    "            \n",
    "        best_score_col_map_dict = {col_idx : np.nan}\n",
    "        \n",
    "        # Returning dict of the best split and their best score with their col idx as key\n",
    "        return split_col_map_dict, best_score_col_map_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for overall best split finding algorithm (Greedy Exact Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_split(data, col_idx_eligible):\n",
    "    \n",
    "    scores_dict = {}\n",
    "    split_val_dict = {}\n",
    "    \n",
    "    # For a subset of columns required\n",
    "    for col_idx in col_idx_eligible:\n",
    "        \n",
    "        split_val_dict_temp, scores_dict_temp = feature_split_algo(data=data, col_idx = col_idx)\n",
    "        \n",
    "        print(scores_dict_temp)\n",
    "        \n",
    "        scores_dict.update(scores_dict_temp)\n",
    "        split_val_dict.update(split_val_dict_temp)\n",
    "        \n",
    "        \n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    best_score_overall = min(scores_dict.values()) # Extracting the mninimum gini score across all columns\n",
    "    best_score_col_idx = [key for key in scores_dict if scores_dict[key] == best_score_overall]\n",
    "    #Extracting the col idx with the best score\n",
    "    \n",
    "    best_col_idx_split_val = split_val_dict[best_score_col_idx[0]]\n",
    "    \n",
    "    # Returning the dictionary with column idx and list of best split gini score and the threshold/splitting cond\n",
    "    return {best_score_col_idx[0]: [best_score_overall, best_col_idx_split_val]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for splitting the current dataframe by the best split found out through the above algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(arr, arr_y, col_idx, split_val):\n",
    "    \n",
    "    # Splitting for X dataframe\n",
    "    x_left = arr[arr[:, col_idx] <= split_val]\n",
    "    x_right = arr[arr[:, col_idx] > split_val]\n",
    "    \n",
    "    # Splitting for y dataframe\n",
    "    y_left = arr_y[arr[:, col_idx] <= split_val]\n",
    "    y_right = arr_y[arr[:, col_idx] > split_val]\n",
    "    \n",
    "    return x_left, x_right, col_idx, split_val, y_left, y_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for the Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cart:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\" in init\")\n",
    "       \n",
    "    # UDF for CART\n",
    "    def grow_tree(self, x_data, y_data, node_dict, max_depth, feat_idx_list = [0,1,4,5,7,9], min_samples_split = 5,\n",
    "                 min_samples_leaf=2,depth=0,input_ads_=input_ads):\n",
    "        \n",
    "        # To restricting going beyond max_depth\n",
    "        if depth <= max_depth:\n",
    "            \n",
    "            print('#------------------------- DEPTH: ', depth, ' -------------------------#')\n",
    "            \n",
    "            #Calculating best split overall\n",
    "            \n",
    "            split_dict = overall_split(data = np.append(x_data, y_data, axis = -1)\n",
    "                                       , col_idx_eligible = feat_idx_list)\n",
    "            \n",
    "            split_col_idx = list(split_dict.keys())[0]\n",
    "            gini_ = list(split_dict.values())[0][0]\n",
    "            split_col_val = gini_ = list(split_dict.values())[0][1]\n",
    "            \n",
    "            #--------------------------------------------------------------------------------------\n",
    "            print('1. ----------------> Entering root_node of depth : ', depth)\n",
    "            \n",
    "            #Splitting on the best split point found\n",
    "            \n",
    "            x_left, x_right, col_idx, split_val, y_left, y_right = split_array(arr=x_data\n",
    "                                                                               , arr_y = y_data\n",
    "                                                                               , col_idx = split_col_idx\n",
    "                                                                               , split_val = split_col_val)\n",
    "            \n",
    "            #defining dictionary for the node of the tree\n",
    "            node_dict = {\n",
    "                \n",
    "                'col': input_ads_.columns[split_col_idx], 'col_idx': split_col_idx,\n",
    "                'threshold': split_col_val, 'val' : np.mean(y_data), 'n_class_0': len(y_data[y_data]==0),\n",
    "                'n_class_1': len(y_data[y_data==1]), 'n_vals': len(y_data)\n",
    "            } #save the information\n",
    "            \n",
    "            print('2. ----------------> First : \\n', node_dict)\n",
    "            \n",
    "            print('3. ----------------> Entering left of depth : ', depth)\n",
    "            \n",
    "            node_dict['left'] = self.grow_tree(x_data=x_left,\n",
    "                                               y_data=y_left,\n",
    "                                               feat_idx_list=feat_idx_list,\n",
    "                                               node_dict={},\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               depth=depth+1)   \n",
    "            #-----------------------------------------------------------------------\n",
    "            if node_dict['left']==None:\n",
    "                print('4. -------> None:\\n')\n",
    "            \n",
    "            # right hand side trees\n",
    "            print('5. -------> Entering right of depth:',depth)\n",
    "            node_dict['right'] = self.grow_tree(x_data=x_right,\n",
    "                                               y_data=y_right,\n",
    "                                               feat_idx_list=feat_idx_list,\n",
    "                                               node_dict={},\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               depth=depth+1)\n",
    "            \n",
    "            if node_dict['right']==None:\n",
    "                print('6. --------> None:\\n')\n",
    "            \n",
    "            #print('After :\\n',node_dict)\n",
    "            #Error Handling\n",
    "            try:\n",
    "                self.depth += 1   # increase the depth since we call fit once\n",
    "            except:\n",
    "                print('7. -------> Entering except---')\n",
    "                return node_dict\n",
    "            \n",
    "        elif depth>max_depth:\n",
    "            return None\n",
    "        \n",
    "        elif (len(y_data)<min_samples_split) | (len(y_data)<min_samples_leaf):\n",
    "            return None\n",
    "        \n",
    "        elif node_dict is None:\n",
    "            return None\n",
    "\n",
    "        \n",
    "        #Returns the fully expanded tree\n",
    "        return node_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the class object and then invoking it for the whole classification tree building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in init\n",
      "#------------------------- DEPTH:  0  -------------------------#\n",
      "{0: 0.47171505085580834}\n",
      "{1: 0.3310508721751884}\n",
      "{4: 0.440020146625283}\n",
      "{5: 0.46906867720264844}\n",
      "{7: 0.4574129473382337}\n",
      "{9: 0.47414944306555556}\n",
      "1. ----------------> Entering root_node of depth :  0\n",
      "2. ----------------> First : \n",
      " {'col': 'Survived', 'col_idx': 1, 'threshold': 0.0, 'val': 0.38636363636363635, 'n_class_0': 792, 'n_class_1': 306, 'n_vals': 792}\n",
      "3. ----------------> Entering left of depth :  0\n",
      "#------------------------- DEPTH:  1  -------------------------#\n",
      "{0: 0.37265443811933374}\n",
      "{1: nan}\n",
      "{4: 0.33847434922703745}\n",
      "{5: 0.3543193271546412}\n",
      "{7: 0.33123223334569263}\n",
      "{9: 0.37575147104496653}\n",
      "1. ----------------> Entering root_node of depth :  1\n",
      "2. ----------------> First : \n",
      " {'col': 'Pclass_3', 'col_idx': 7, 'threshold': 0.3, 'val': 0.7491039426523297, 'n_class_0': 279, 'n_class_1': 209, 'n_vals': 279}\n",
      "3. ----------------> Entering left of depth :  1\n",
      "#------------------------- DEPTH:  2  -------------------------#\n",
      "{0: 0.31660441426146}\n",
      "{1: nan}\n",
      "{4: 0.2969146460475941}\n",
      "{5: 0.3080478345184227}\n",
      "{7: 0.3190103509214845}\n",
      "{9: 0.31973421926910295}\n",
      "1. ----------------> Entering root_node of depth :  2\n",
      "2. ----------------> First : \n",
      " {'col': 'Fare', 'col_idx': 4, 'threshold': 0.0, 'val': 0.8, 'n_class_0': 250, 'n_class_1': 200, 'n_vals': 250}\n",
      "3. ----------------> Entering left of depth :  2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 1\n",
      "#------------------------- DEPTH:  2  -------------------------#\n",
      "{0: 0.39091511936339524}\n",
      "{1: nan}\n",
      "{4: 0.27586206896551707}\n",
      "{5: nan}\n",
      "{7: 0.40583554376657827}\n",
      "{9: nan}\n",
      "1. ----------------> Entering root_node of depth :  2\n",
      "2. ----------------> First : \n",
      " {'col': 'Fare', 'col_idx': 4, 'threshold': 0.0, 'val': 0.3103448275862069, 'n_class_0': 29, 'n_class_1': 9, 'n_vals': 29}\n",
      "3. ----------------> Entering left of depth :  2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 0\n",
      "#------------------------- DEPTH:  1  -------------------------#\n",
      "{0: 0.30415432842779827}\n",
      "{1: nan}\n",
      "{4: 0.2891642204708224}\n",
      "{5: 0.30622009569378}\n",
      "{7: 0.3022124119303341}\n",
      "{9: 0.303683184569611}\n",
      "1. ----------------> Entering root_node of depth :  1\n",
      "2. ----------------> First : \n",
      " {'col': 'Fare', 'col_idx': 4, 'threshold': 0.0, 'val': 0.18908382066276802, 'n_class_0': 513, 'n_class_1': 97, 'n_vals': 513}\n",
      "3. ----------------> Entering left of depth :  1\n",
      "#------------------------- DEPTH:  2  -------------------------#\n",
      "{0: 0.2387401820774909}\n",
      "{1: nan}\n",
      "{4: nan}\n",
      "{5: 0.2400903486038945}\n",
      "{7: 0.23635254521663485}\n",
      "{9: 0.23880749566535098}\n",
      "1. ----------------> Entering root_node of depth :  2\n",
      "2. ----------------> First : \n",
      " {'col': 'Pclass_3', 'col_idx': 7, 'threshold': 0.1, 'val': 0.1396508728179551, 'n_class_0': 401, 'n_class_1': 56, 'n_vals': 401}\n",
      "3. ----------------> Entering left of depth :  2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 1\n",
      "#------------------------- DEPTH:  2  -------------------------#\n",
      "{0: 0.4293267651888342}\n",
      "{1: nan}\n",
      "{4: nan}\n",
      "{5: nan}\n",
      "{7: 0.46099656357388313}\n",
      "{9: nan}\n",
      "1. ----------------> Entering root_node of depth :  2\n",
      "2. ----------------> First : \n",
      " {'col': 'PassengerId', 'col_idx': 0, 'threshold': 186.0, 'val': 0.36607142857142855, 'n_class_0': 112, 'n_class_1': 41, 'n_vals': 112}\n",
      "3. ----------------> Entering left of depth :  2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n"
     ]
    }
   ],
   "source": [
    "cart_ = cart()\n",
    "tree_dict_ = cart_.grow_tree(x_data=X_arr,\n",
    "                             y_data=y_arr,\n",
    "                             node_dict={},\n",
    "                             max_depth=2,\n",
    "                             input_ads_=input_ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for prediction of a single row in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col': 'Survived',\n",
       " 'col_idx': 1,\n",
       " 'threshold': 0.0,\n",
       " 'val': 0.38636363636363635,\n",
       " 'n_class_0': 792,\n",
       " 'n_class_1': 306,\n",
       " 'n_vals': 792,\n",
       " 'left': {'col': 'Pclass_3',\n",
       "  'col_idx': 7,\n",
       "  'threshold': 0.3,\n",
       "  'val': 0.7491039426523297,\n",
       "  'n_class_0': 279,\n",
       "  'n_class_1': 209,\n",
       "  'n_vals': 279,\n",
       "  'left': {'col': 'Fare',\n",
       "   'col_idx': 4,\n",
       "   'threshold': 0.0,\n",
       "   'val': 0.8,\n",
       "   'n_class_0': 250,\n",
       "   'n_class_1': 200,\n",
       "   'n_vals': 250,\n",
       "   'left': None,\n",
       "   'right': None},\n",
       "  'right': {'col': 'Fare',\n",
       "   'col_idx': 4,\n",
       "   'threshold': 0.0,\n",
       "   'val': 0.3103448275862069,\n",
       "   'n_class_0': 29,\n",
       "   'n_class_1': 9,\n",
       "   'n_vals': 29,\n",
       "   'left': None,\n",
       "   'right': None}},\n",
       " 'right': {'col': 'Fare',\n",
       "  'col_idx': 4,\n",
       "  'threshold': 0.0,\n",
       "  'val': 0.18908382066276802,\n",
       "  'n_class_0': 513,\n",
       "  'n_class_1': 97,\n",
       "  'n_vals': 513,\n",
       "  'left': {'col': 'Pclass_3',\n",
       "   'col_idx': 7,\n",
       "   'threshold': 0.1,\n",
       "   'val': 0.1396508728179551,\n",
       "   'n_class_0': 401,\n",
       "   'n_class_1': 56,\n",
       "   'n_vals': 401,\n",
       "   'left': None,\n",
       "   'right': None},\n",
       "  'right': {'col': 'PassengerId',\n",
       "   'col_idx': 0,\n",
       "   'threshold': 186.0,\n",
       "   'val': 0.36607142857142855,\n",
       "   'n_class_0': 112,\n",
       "   'n_class_1': 41,\n",
       "   'n_vals': 112,\n",
       "   'left': None,\n",
       "   'right': None}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_row_pred(test_x_,max_depth,temp_tree_dict): #Takes in the tree dict from training\n",
    "\n",
    "    for i in range(max_depth): #For all depth\n",
    "        \n",
    "        #print('------ depth :',i)\n",
    "        threshold = temp_tree_dict['threshold']\n",
    "        split_col_idx = temp_tree_dict['col_idx']\n",
    "\n",
    "        tree_dict_left = temp_tree_dict['left']\n",
    "        tree_dict_right = temp_tree_dict['right']\n",
    "        \n",
    "        #Traversing into left side\n",
    "        if (test_x_[split_col_idx]<=threshold) & (tree_dict_left!=None) & (tree_dict_right!=None):\n",
    "\n",
    "            temp_tree_dict = tree_dict_left\n",
    "\n",
    "            if (temp_tree_dict['left']==None) & (temp_tree_dict['right']==None):\n",
    "                prediction = temp_tree_dict['val']\n",
    "                #pred_list.append(prediction)\n",
    "\n",
    "        #Traversing into right side\n",
    "        elif (test_x_[split_col_idx]>threshold) & (tree_dict_left!=None) & (tree_dict_right!=None):\n",
    "\n",
    "            temp_tree_dict = tree_dict_right\n",
    "\n",
    "            if (temp_tree_dict['left']==None) & (temp_tree_dict['right']==None):\n",
    "                prediction = temp_tree_dict['val']\n",
    "                #pred_list.append(prediction)\n",
    "\n",
    "        #If end of the tree is reached, generate predictions \n",
    "        elif (tree_dict_left==None) & (tree_dict_right==None):\n",
    "\n",
    "            prediction = temp_tree_dict['val']\n",
    "            \n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF for overall prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tree(test_data,max_depth,tree_object=tree_dict_,threshold=0.5): #Takes in tree dictionary and threshold of proabability\n",
    "    \n",
    "    pred_list = []\n",
    "    \n",
    "    #For each row in test data\n",
    "    for idx in range(len(test_data)):\n",
    "        \n",
    "        #Sngle row prediction calculation\n",
    "        pred = np.round(single_row_pred(test_x_=test_data[idx],\n",
    "                                        max_depth=max_depth,\n",
    "                                        temp_tree_dict=tree_object),3)\n",
    "        pred_list.append(pred)\n",
    "        \n",
    "    print('Length of preds :',len(pred_list))\n",
    "    \n",
    "    #Converting into array\n",
    "    pred_proba = np.array(pred_list)\n",
    "    \n",
    "    #Converting into class predictions (binary) based on threshold\n",
    "    pred_list = (np.array(pred_proba)>threshold).astype(int)\n",
    "        \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from the Decision Tree built from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of preds : 100\n",
      "Total predictions : 100\n",
      "Unique of predictions : [0 1]\n",
      "1. ROC AUC: 0.779\n",
      "2. Accuracy : 0.81\n",
      "3. Classification Report -\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        64\n",
      "           1       0.77      0.67      0.72        36\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.80      0.78      0.79       100\n",
      "weighted avg       0.81      0.81      0.81       100\n",
      "\n",
      "4. Confusion Matrix - \n",
      " [[57  7]\n",
      " [12 24]]\n"
     ]
    }
   ],
   "source": [
    "preds_manual = predict_tree(test_data=X_test_arr\n",
    "                            ,max_depth=2,\n",
    "                            tree_object=tree_dict_,\n",
    "                            threshold=0.5)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "print('Total predictions :', len(preds_manual))\n",
    "print('Unique of predictions :',np.unique(preds_manual))\n",
    "preds_manual[0:10]\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "#Evaluating the model\n",
    "score = roc_auc_score(y_test_arr, preds_manual)\n",
    "print('1. ROC AUC: %.3f' % score)\n",
    "print('2. Accuracy :',accuracy_score(y_test_arr, preds_manual))\n",
    "print('3. Classification Report -\\n',classification_report(y_test_arr, preds_manual))\n",
    "print('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, preds_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ROC AUC: 0.779\n",
      "2. Accuracy : 0.81\n",
      "3. Classification Report -\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        64\n",
      "           1       0.77      0.67      0.72        36\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.80      0.78      0.79       100\n",
      "weighted avg       0.81      0.81      0.81       100\n",
      "\n",
      "4. Confusion Matrix - \n",
      " [[57  7]\n",
      " [12 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=100,max_depth=2,min_samples_split=5,min_samples_leaf=2)\n",
    "dt_clf.fit(X_arr[:,[0,1,4,5,7,9]],y_arr)\n",
    "\n",
    "sklearn_preds = dt_clf.predict(X_test_arr[:,[0,1,4,5,7,9]])\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#Evaluating the model\n",
    "score = roc_auc_score(y_test_arr, sklearn_preds)\n",
    "print('1. ROC AUC: %.3f' % score)\n",
    "print('2. Accuracy :',accuracy_score(y_test_arr, sklearn_preds))\n",
    "print('3. Classification Report -\\n',classification_report(y_test_arr, sklearn_preds))\n",
    "print('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, sklearn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
